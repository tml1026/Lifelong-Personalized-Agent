# Lifelong-Personalized-Agent

The **Lifelong-Personalized-Agent (LPA)** project is a sophisticated framework designed to simulate and develop personalized AI agents. These agents can dynamically adjust their interactions based on evolving user personas, ensuring a highly customized and adaptive experience.

The core of this project is a pipeline that automates data generation, query simulation, and model learning, making it a powerful tool for research and development in the field of personalized AI.

## Introduction

This repository provides a Lifelong-Personalized-Agent framework for creating personalized agents that can manage user personas, simulate interactions, and adapt behavior based on evolving user chat history. The LPA's functionality is supported by a well-structured architecture involving modules for persona management, user simulation, and chatbot interaction.

## Project Structure

```plaintext
Lifelong-Personalized-Agent/
├── data/
│   └── generated/                # Generated datasets for personas and scenes
├── modules/
│   ├── agent.py                  # Core agent logic
│   ├── conversation_manager.py   # Manages conversation flow
│   ├── persona_manager.py        # Manages loading and updating personas
│   ├── personalized_agent.py     # Integrates persona-specific behavior
│   ├── tool_simulator.py         # Simulates API/tool responses
│   └── user_simulator.py         # Simulates user interactions
├── pipeline.sh                   # Main execution script for the pipeline
├── seed_generator.py             # Generate seed data
├── query_generator.py            # Generate test queries
├── unified_main.py
```

## Environment Setup

Before running the project, you need to set up the required environment variables and install the dependencies.

### 1. Environment Variables

You must configure the following environment variables:

```bash
export OPENAI_API_KEY="your_api_key"
export OPENAI_API_BASE="your_api_base_url"
```

You can also set an optional `OPENAI_MODEL` variable to specify the model to use (e.g., `gpt-4`). If not set, it defaults to `gpt-4o-mini`.

### 2. Install Dependencies

Install the necessary Python packages using `requirements.txt`:

```bash
pip install -r requirements.txt
```

## Quick Start

The entire LPA pipeline can be run using the `pipeline.sh` script. This script automates the process of data generation, query creation, and agent learning.

```bash
bash pipeline.sh
```

## Step-by-Step Execution

Alternatively, you can run each step of the pipeline manually.

### 1. Generate Seed Data

First, generate the dataset containing personas and scenes. This will be used as input for the next steps.

```bash
python seed_generator.py 
    --mode complete \
    --output_dir data/generated \
     --num_personas 5 -\
     -scenes_per_persona 10 \
     --filename complete_dataset.json
```

- `--num_personas`: Specifies the number of personas to generate.
- `--scenes_per_persona`: Specifies the number of scenes for each persona.
- `--output_dir`: The directory where the generated data will be saved.

### 2. Generate Queries

Next, generate test queries based on the personas from the dataset created in the previous step.

```bash
python query_generator.py 
    --persona_db data/generated/complete_dataset.json \
    --output_dir test_query_output \
    --format json
```

- `--persona_db`: Path to the dataset generated by `seed_generator.py`.
- `--output_dir`: The directory where the query files will be saved.

### 3. Run the Learning Process

Finally, run the learning process for a specific persona. You will need to run this command for each persona you want the agent to learn from. Remember to set the required environment variables (`OPENAI_API_KEY`, `OPENAI_API_BASE`) beforehand.

```bash
python unified_main.py \
    --persona test_query_output/persona_001.json \
    --persona_db test_query_output/persona_001_db.json \
    --openai_api_key "$OPENAI_API_KEY" \
    --openai_api_base "$OPENAI_API_BASE" \
    --model_name "gpt-4o-mini" \
    --log_dir "logs_pipeline"
```
- `--persona`: Path to the specific persona query file (e.g., `persona_001.json`).
- `--persona_db`: Path to the corresponding persona database file.
- `--log_dir`: Directory to store logs for the run.

## Architecture Overview

The **Lifelong-Personalized-Agent** framework is built around several core components:

### 1. **Chatbot**
- The `Chatbot` class serves as the basic functional agent, providing core functionalities for managing conversations, formatting prompts, requesting LLMs, and maintaining session histories.

### 2. **PersonalizedChatbot**
- Inherits from the base `Chatbot` class and extends its capabilities by integrating with the `PersonaManager`. It handles the creation of prompts based on the user's persona and the scene.

### 3. **PersonaManager**
- Manages the storage and retrieval of user personas from a database, ensuring that the agent's responses are aligned with the user's profile.

### 4. **User Simulator**
- The `user_simulator.py` module simulates user interactions to test and refine agent responses in a controlled environment.

### 5. **Persona**
- Represents the user's persona, including demographic data, personality traits, behavioral patterns, and preferences.
